# -*- coding: utf-8 -*-
"""Self analysis mental health.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x68nZYhMhwyPJCPCxQ6hmRGD6wG6K4Ic
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import shap
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
import gradio as gr

# Load dataset
df = pd.read_csv("survey.csv")

# Data Cleaning & Preprocessing
df = df.dropna()
le = LabelEncoder()
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

# Define features and target variable
X = df.drop(columns=['treatment'])
y = df['treatment']

# Split dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# Train Logistic Regression model
logreg_model = LogisticRegression(max_iter=200, random_state=42)
logreg_model.fit(X_train, y_train)
y_pred_logreg = logreg_model.predict(X_test)

# Model Evaluation
models = {'Random Forest': y_pred_rf, 'Logistic Regression': y_pred_logreg}
for name, y_pred in models.items():
    print(f"\n{name} Performance:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print(f"Precision: {precision_score(y_test, y_pred):.4f}")
    print(f"Recall: {recall_score(y_test, y_pred):.4f}")
    print(f"F1-score: {f1_score(y_test, y_pred):.4f}")
    print(f"ROC-AUC: {roc_auc_score(y_test, y_pred):.4f}")
    print(classification_report(y_test, y_pred))

# Save model
joblib.dump(rf_model, "mental_health_model.pkl")

explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test)

# Load T5 model for LLM Experimentation
tokenizer = T5Tokenizer.from_pretrained("t5-small")
model = T5ForConditionalGeneration.from_pretrained("t5-small")

def llm_explanation(prediction):
    input_text = f"Explain mental health condition: {prediction}"
    input_ids = tokenizer(input_text, return_tensors="pt").input_ids
    output = model.generate(input_ids)
    return tokenizer.decode(output[0], skip_special_tokens=True)

# Define a function for prediction
def predict_mental_health(symptoms):
    symptoms_df = pd.DataFrame([symptoms], columns=X.columns)
    prediction = rf_model.predict(symptoms_df)[0]
    explanation = llm_explanation(prediction)
    return prediction, explanation

# Gradio UI
def gradio_interface(*features):
    symptoms = list(features)
    prediction, explanation = predict_mental_health(symptoms)
    return f"Predicted Condition: {prediction}\n\nExplanation: {explanation}"

inputs = [gr.Textbox(label=col) for col in X.columns]
outputs = gr.Textbox()
interface = gr.Interface(fn=gradio_interface, inputs=inputs, outputs=outputs, title="Mental Health Predictor")
interface.launch(share=True)

